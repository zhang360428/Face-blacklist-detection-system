import cv2
import numpy as np
from insightface.app import FaceAnalysis
from config import DEVICE, DETSCOREBAR  # ç¡®ä¿å¯¼å…¥é…ç½®

class FaceRecognitionModel:
    def __init__(self, model_name="buffalo_l", device=DEVICE):
        """åˆå§‹åŒ–ArcFaceæ¨¡å‹ï¼Œå¼ºåˆ¶ä½¿ç”¨æŒ‡å®šè®¾å¤‡"""
        
        # æ ¹æ®è®¾å¤‡é…ç½®providers
        if "cuda" in device.lower():
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            ctx_id = 0  # GPU device id
            print(f"ğŸš€ å°è¯•ä½¿ç”¨GPU: {device}")
        else:
            providers = ['CPUExecutionProvider']
            ctx_id = -1
            print(f"ğŸ’» ä½¿ç”¨CPU")
        
        # åˆå§‹åŒ–æ¨¡å‹å¹¶å¼ºåˆ¶æŒ‡å®šproviders
        self.app = FaceAnalysis(name=model_name, providers=providers)
        
        # å‡†å¤‡æ¨¡å‹æ—¶æ˜ç¡®æŒ‡å®šè®¾å¤‡
        self.app.prepare(ctx_id=ctx_id, det_size=(640, 640))
        
        # éªŒè¯å®é™…ä½¿ç”¨çš„è®¾å¤‡
        session = self.app.models['detection'].session
        actual_providers = session.get_providers()
        print(f"âœ… æ¨¡å‹å®é™…ä½¿ç”¨: {actual_providers[0]}")
        
        if 'CUDAExecutionProvider' not in actual_providers:
            print("âš ï¸ è­¦å‘Šï¼šæœªä½¿ç”¨GPUï¼Œè¯·æ£€æŸ¥CUDAå’Œonnxruntime-gpuå®‰è£…")


    def _preprocess_image(self, img):
        """å›¾åƒé¢„å¤„ç†ï¼šå»å™ªã€é”åŒ–ã€é¢œè‰²æ ¡æ­£"""
        
        # 1. éå±€éƒ¨å‡å€¼å»å™ªï¼ˆä¿ç•™ç»†èŠ‚ï¼Œé€‚åˆè‡ªç„¶å›¾åƒï¼‰
        #    h=10: é¢œè‰²å¼ºåº¦å»å™ªå¼ºåº¦, templateWindowSize=7, searchWindowSize=21
        denoised = cv2.fastNlMeansDenoisingColored(img, None, h=10, 
                                                    templateWindowSize=7, 
                                                    searchWindowSize=21)
        
        # 2. é”åŒ–ï¼ˆè¡¥å¿å»å™ªå¯¼è‡´çš„è½»å¾®æ¨¡ç³Šï¼‰
        kernel = np.array([[-0.1,-0.1,-0.1],
                        [-0.1, 2.0,-0.1],
                        [-0.1,-0.1,-0.1]])
        sharpened = cv2.filter2D(denoised, -1, kernel)
        
        # 3. å¯¹æ¯”åº¦å—é™è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ˆCLAHEï¼‰
        #    æ”¹å–„å…‰ç…§ä¸å‡ï¼Œæå‡ä½å…‰ç…§åŒºåŸŸç»†èŠ‚
        lab = cv2.cvtColor(sharpened, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        enhanced = cv2.merge([l, a, b])
        img_enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        
        # 4. äº®åº¦/å¯¹æ¯”åº¦å¾®è°ƒï¼ˆå¯é€‰ï¼Œé˜²æ­¢è¿‡æ›/è¿‡æš—ï¼‰
        #    alpha: å¯¹æ¯”åº¦ (1.0-3.0), beta: äº®åº¦ (0-100)
        alpha, beta = 1.2, 10
        adjusted = cv2.convertScaleAbs(img_enhanced, alpha=alpha, beta=beta)
        
        return adjusted
    

    def extract_feature(self, image_path, use_enhancement=True):
        # ...ï¼ˆä¿æŒä¸å˜ï¼‰...
        img = cv2.imread(image_path)
        if img is None:
            return False, None, None
        
        # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé˜²æ­¢å¡æ­»
        try:
            faces = self.app.get(img)
        except Exception as e:
            print(f"âŒ å¤„ç† {image_path} æ—¶å‡ºé”™: {e}")
            return False, None, None
        
        if len(faces) == 0 or faces[0].det_score < DETSCOREBAR:
            if use_enhancement:
                img = self._preprocess_image(img)
                faces = self.app.get(img)
                if len(faces) != 0:
                    face = faces[0]
                    embedding = face.embedding
                    bbox = face.bbox
                    return True, embedding, bbox
            return False, None, None
        
        face = faces[0]
        # print(face)
        embedding = face.embedding
        bbox = face.bbox
        
        return True, embedding, bbox
    
    # ...ï¼ˆå…¶ä½™æ–¹æ³•ä¿æŒä¸å˜ï¼‰...

    def detect_face(self, image_path):
        """æ£€æµ‹å›¾ç‰‡ä¸­æ˜¯å¦æœ‰äººè„¸"""
        img = cv2.imread(image_path)
        if img is None:
            return False

        faces = self.app.get(img)
        return len(faces) > 0
